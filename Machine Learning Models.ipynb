{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e895b50e-77aa-4c00-bda6-f727313c84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f8604a-f097-45b3-9981-644aa3f135f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"TelcoCustomerChurn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae1cb5c-7a7f-487f-a138-11716562745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(columns=['customerID'], errors='ignore', inplace=True)\n",
    "\n",
    "# Convert 'Churn' to binary values\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6e1a43-8d7e-4b4e-b6d1-7fda95d7b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target variable\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f44dc95-ade7-4645-866c-8527b420a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5634, 6559) y_train shape: (5634,)\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)  # Debugging dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007d710f-d7ac-4689-b763-419d80430d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Learning Models\n",
    "models = {\n",
    "    \"Baseline - Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Artificial Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af28676d-a336-45dc-a4b4-8f3bedf15512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models...\n",
      "\n",
      "Baseline - Logistic Regression Accuracy: 0.7842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      1036\n",
      "           1       0.61      0.51      0.56       373\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.70      0.71      1409\n",
      "weighted avg       0.77      0.78      0.78      1409\n",
      "\n",
      "Decision Tree Accuracy: 0.7807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      1036\n",
      "           1       0.60      0.50      0.54       373\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.69      0.70      1409\n",
      "weighted avg       0.77      0.78      0.77      1409\n",
      "\n",
      "Random Forest Accuracy: 0.7913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87      1036\n",
      "           1       0.66      0.45      0.53       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.68      0.70      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandh\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:05:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1036\n",
      "           1       0.62      0.52      0.56       373\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.73      0.70      0.71      1409\n",
      "weighted avg       0.78      0.79      0.78      1409\n",
      "\n",
      "Support Vector Machine Accuracy: 0.7353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1036\n",
      "           1       0.50      0.76      0.60       373\n",
      "\n",
      "    accuracy                           0.74      1409\n",
      "   macro avg       0.70      0.74      0.70      1409\n",
      "weighted avg       0.79      0.74      0.75      1409\n",
      "\n",
      "Artificial Neural Network Accuracy: 0.7480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1036\n",
      "           1       0.63      0.12      0.20       373\n",
      "\n",
      "    accuracy                           0.75      1409\n",
      "   macro avg       0.69      0.55      0.52      1409\n",
      "weighted avg       0.72      0.75      0.68      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "print(\"\\nTraining models...\\n\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f9accc-5fe6-447a-b2bf-95532095ea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Grid Search for Random Forest...\n",
      "\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "Grid Search Completed!\n",
      "Best Random Forest Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Applying K-Means Clustering...\n",
      "\n",
      "K-Means Silhouette Score: 0.2379\n",
      "\n",
      "Script completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Reduced grid for quick testing\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"\\nStarting Grid Search for Random Forest...\\n\")\n",
    "    rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "    rf_grid_search.fit(X_train, y_train)\n",
    "    print(\"\\nGrid Search Completed!\")\n",
    "    print(\"Best Random Forest Parameters:\", rf_grid_search.best_params_)\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during Grid Search:\", e)\n",
    "\n",
    "# Unsupervised Learning - Clustering with K-Means\n",
    "try:\n",
    "    print(\"\\nApplying K-Means Clustering...\\n\")\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train)\n",
    "    kmeans_labels = kmeans.predict(X_test)\n",
    "    silhouette = silhouette_score(X_test, kmeans_labels)\n",
    "    print(f\"K-Means Silhouette Score: {silhouette:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during K-Means:\", e)\n",
    "\n",
    "print(\"\\nScript completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dea6a-d005-46ca-81f4-9e3d9dd5755b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
